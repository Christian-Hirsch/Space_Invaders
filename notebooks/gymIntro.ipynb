{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an introduction to [opengym](https://gym.openai.com/), an accessible and flexible framework for problems in reinforcement learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large part of the material from this notebook is modified from the excellent [official tutorial](http://gym.openai.com/docs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As guiding example, we rely on the [**cartpole game** ](https://github.com/openai/gym/wiki/CartPole-v0). The goal of this game is to stabilize a rod attached on one end to a movable cart by carefully moving the cart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pytorch.org/tutorials/_images/cartpole1.gif\" alt=\"Drawing\" style=\"width: 700px;\"></img>\n",
    "Source: https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core concept of opengym is that of *environment* that an agent can interact with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most central components of an environment are the **observation space** and the **action space**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **observation space** formalizes what information an agent can draw from the environment. In the cartpole example observations are four-dimensional vectors describing the location and velocity of the cart, and angle and angular velocity of the pole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **action space** formalizes how the agent may interact with the environment. In the cartpole example there are only two possible actions: pushing the car to the left or to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space) \n",
    "print(env.observation_space.sample())\n",
    "print(env.action_space) \n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, the agent can interact with the environment by performing repeatedly random actions until the environment terminates. A sequence of action until termination is called **episode**.\n",
    "\n",
    "Each time an action is performed, an agent receives feedback from the environment, namely the current **observed state**, the **reward** for the action and information about whether the environment has terminated. In the cartpole example, the environment terminates if the angle of the rod deviates too much from the vertical position. The agent receives a reward of 1 per step as long as the environment has not terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "seed = 42\n",
    "\n",
    "env.seed(seed)\n",
    "env.reset()\n",
    "\n",
    "for _ in range(steps):\n",
    "    env.render()\n",
    "    a = env.action_space.sample()\n",
    "    s, r, done, _ = env.step(a)\n",
    "    print(s, r, done)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Example: Space Invaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second example, let's move to `Space Invaders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation space is much larger than in the cartpole example. Indeed, the observation space is now an RGB $210 \\times 160$-RGB pixel image. Since ``Space Invaders`` is part of the atari family, there are 6 possible actions corresponding to four directions and two buttons. However, only three of the actions have an effect, namely ``left``, ``right`` and ``shoot``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can perform random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(8e2)\n",
    "seed = 42\n",
    "\n",
    "env.seed(seed)\n",
    "env.reset()\n",
    "for _ in range(steps):\n",
    "    env.render()\n",
    "    a = env.action_space.sample()\n",
    "    s, r, done, _ = env.step(a)\n",
    "env.close()\n",
    "\n",
    "print(r, done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
