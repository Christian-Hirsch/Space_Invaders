{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [previous notebook](./ucb.ipynb), we have learned how UCB can identify quickly the optimal arm in classical [Multi-Armed Bandits](https://banditalgs.com/2016/09/18/the-upper-confidence-bound-algorithm/). Now, we learn how [Thompson Sampling]() -- developed by [W. Thompson]() in 1933 -- leverages a Bayesian perspective to tackle this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to determining the optimal arm, the Bayesian viewpoint also allows to create confidence intervals for the parameters of the underlying bandit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely, we assume that we have a prior intuition on kind of bandits we may encounter in our application scenario. This belief is encoded in a **prior distribution** $Q(\\theta)$ over all bandits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we play a given bandit for $N$ rounds by performing actions $A_1, A_2, \\dots, A_n$ and receiving rewards $R_1, R_2, \\dots, R_n$. This data should lead to us to update our initial, potentially na√Øve, prior beliefs. This leads to a **posterior distribution** $Q(\\theta | A_1, R_1, \\dots, A_n, R_n)$ computed via [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem):\n",
    "$$Q(\\theta |  A_1, R_1, \\dots, A_n, R_n) = \\frac{Q(\\theta ,  A_1, R_1, \\dots, A_n, R_n)}{\\int_\\theta Q(A_1, R_1, \\dots, A_n, R_n|\\theta) Q(\\theta) {\\rm d}\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thompson sampling is based on two simple steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample parameter from the posterior**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick the arm with the highest reward under this parameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Beta-Bernoulli bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the general idea at a specific example, we present *Beta-Bernoulli Bandits* following the lucid blogpost by [Peter Roelants](https://peterroelants.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely, a Bernoulli bandit returns rewards in $\\{0, 1\\}$ and we write $\\mu_i$ for the success probability of the $i$th arm. We use a $\\mathsf{Beta}(\\alpha, \\beta)$ prior for each $\\mu_i$, [recalling](https://en.wikipedia.org/wiki/Beta_distribution) that the $\\mathsf{Beta}(\\alpha, \\beta)$ distribution is a probability distribution on $[0, 1]$ with unnormalized density\n",
    "$$p_{\\alpha, \\beta}(x) \\propto x^{\\alpha - 1}(1 - x)^{\\beta - 1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beta distribution is particularly popular in Bayesian contexts, since the posterior distribution is again a beta distribution with adapted parameters. More precisely, if an arm was played $k \\le n$ times with $s \\le k$ successes, then the posterior is a $\\mathsf{Beta}(\\alpha + s, \\beta + (k - s))$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simulation, we initialize the Bayesian parameters as $\\alpha = \\beta = 1$. We take a specific 2-armed Bernoulli-bandit with success probabilities $\\mu_1 = 0.5$ and $\\mu_2 = 0.55$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "#initial beta parameters\n",
    "alphas = np.ones(2)\n",
    "betas = np.ones(2)\n",
    "\n",
    "#success probs\n",
    "mus = [.5, .55]\n",
    "\n",
    "#episodes\n",
    "N = 1000\n",
    "\n",
    "#action trace\n",
    "trace_a = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we play the bandit for $N = 1000$ episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.zeros(2)\n",
    "ss = np.zeros(2)\n",
    "\n",
    "for _ in range(N):\n",
    "    #sample parameters according to posterior\n",
    "    succ_probs = np.random.beta(alphas + ss, betas + ks - ss)\n",
    "\n",
    "    #select action with highest success probability\n",
    "    a = np.argmax(succ_probs)\n",
    "\n",
    "    #retrieve rewards\n",
    "    r = np.random.rand() < mus[a]\n",
    "\n",
    "    #update history\n",
    "    ks[a] += 1\n",
    "    ss[a] += r\n",
    "\n",
    "    #remember actions\n",
    "    trace_a += [a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the trace reveals that Thompson sampling quickly identifies arm 1 as the optimal arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ff9207c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.lineplot(np.arange(N), trace_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
